<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/pokerl/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=pokerl/livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  RL Algorithm and Policy
  #

For training, I adopted the on-policy algorithm Proximal Policy Optimization (PPO). PPO supports vectorized environments well and there is a large amount of online code examples surrounding it.
I tried to keep the policy itself simple. I wanted a policy that

Could have some way of processing sequential (time) data.
Was small for faster training.

To handle time dependence I considered a few options:

Modify my observation to stack frames. Each frame would linearly increase the model’s input. Then use some form of model that handles batches of sequential data, e.g., a 3D CNN or attention layer. These models would have heavily slowed down training and require more VRAM than I had at the time
Use a recurrent neural network such as an LSTM.
Use a state space model (SSM).

I went with the easiest to integrate solution, an LSTM. An LSTM contains an internal state that gets input to the model alongside the most recent data point. Although LSTMs can only remember up to ≈1000 steps, that was enough history for an effective policy.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/pokerl/docs/chapter-2/policy/">
  <meta property="og:site_name" content="Pokémon RL">
  <meta property="og:title" content="Policy">
  <meta property="og:description" content="RL Algorithm and Policy # For training, I adopted the on-policy algorithm Proximal Policy Optimization (PPO). PPO supports vectorized environments well and there is a large amount of online code examples surrounding it.
I tried to keep the policy itself simple. I wanted a policy that
Could have some way of processing sequential (time) data. Was small for faster training. To handle time dependence I considered a few options:
Modify my observation to stack frames. Each frame would linearly increase the model’s input. Then use some form of model that handles batches of sequential data, e.g., a 3D CNN or attention layer. These models would have heavily slowed down training and require more VRAM than I had at the time Use a recurrent neural network such as an LSTM. Use a state space model (SSM). I went with the easiest to integrate solution, an LSTM. An LSTM contains an internal state that gets input to the model alongside the most recent data point. Although LSTMs can only remember up to ≈1000 steps, that was enough history for an effective policy.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">
<title>Policy | Pokémon RL</title>
<link rel="icon" href="/pokerl/favicon.png" >
<link rel="manifest" href="/pokerl/manifest.json">
<link rel="canonical" href="http://localhost:1313/pokerl/docs/chapter-2/policy/">
<link rel="stylesheet" href="/pokerl/book.min.20566c4d69204c7b44949aa70a954a16ae963f6de14a8871d403b3c690ffd867.css" integrity="sha256-IFZsTWkgTHtElJqnCpVKFq6WP23hSohx1AOzxpD/2Gc=" crossorigin="anonymous">
  <script defer src="/pokerl/fuse.min.js"></script>
  <script defer src="/pokerl/en.search.min.1cf198c8682c4283df4c3320ac96d752b44ec2cbf9a5a9a4b481b988efcecfa8.js" integrity="sha256-HPGYyGgsQoPfTDMgrJbXUrROwsv5pamktIG5iO/Oz6g=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/pokerl/"><span>Pokémon RL</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>















  
  <ul>
    
      
        <li>
          
  
  

  
    <span>Chapter 1: RL and the Pokémon Environment</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-1/the-loop/" class="">RL Quickstart</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-1/env-setup/" class="">Setting up the Environment</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <span>Breaking Down Pokémon</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-1/breakdown/intro/" class="">Intro</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-1/breakdown/battling/" class="">Battling</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-1/breakdown/8badges/" class="">The 8 Badges</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-1/breakdown/field_interactions/" class="">Field Interactions and Exploration</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-1/breakdown/team_rocket/" class="">Team Rocket</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-1/breakdown/route/" class="">The &#34;Route&#34;</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-1/breakdown/risk_management/" class="">Risk Management</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>Chapter 2: Observations, Rewards, and Policy</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-2/observations/" class="">Observations</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-2/rewards/" class="">Rewards</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-2/policy/" class="active">Policy</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>Chapter 3: Building and Running the System</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-3/running/" class="">Running</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-3/reading-ram/" class="">Reading RAM</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-3/metrics/" class="">Metrics and Visualization</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-3/swarm/" class="">The Swarm</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>Chapter 4: Concluding Thoughts</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-4/results/" class="">Results</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/pokerl/docs/chapter-4/future/" class="">Future</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>














</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/pokerl/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Policy</h3>

  <label for="toc-control">
    
    <img src="/pokerl/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#feature-engineering-the-policy">Feature Engineering the Policy</a>
      <ul>
        <li><a href="#Pokémon-red-policy">Pokémon Red Policy</a></li>
      </ul>
    </li>
    <li><a href="#the-cnn">The CNN</a></li>
    <li><a href="#one-hot-encoding">One-Hot encoding</a></li>
    <li><a href="#embeddings">Embeddings</a></li>
    <li><a href="#party-network">Party Network</a></li>
    <li><a href="#binary-vectors">Binary Vectors</a></li>
    <li><a href="#safari-steps">Safari Steps</a></li>
    <li><a href="#final-model-layers">Final Model Layers</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="rl-algorithm-and-policy">
  RL Algorithm and Policy
  <a class="anchor" href="#rl-algorithm-and-policy">#</a>
</h1>
<p>For training, I adopted the <a href="https://towardsdatascience.com/on-policy-v-s-off-policy-learning-75089916bc2f/">on-policy</a> algorithm <a href="https://en.wikipedia.org/wiki/Proximal_policy_optimization">Proximal Policy Optimization</a> (PPO). PPO supports vectorized environments well and there is a large amount of online code examples surrounding it.</p>
<p>I tried to keep the policy itself simple. I wanted a policy that</p>
<ul>
<li>Could have some way of processing sequential (time) data.</li>
<li>Was small for faster training.</li>
</ul>
<p>To handle time dependence I considered a few options:</p>
<ul>
<li>Modify my observation to stack frames. Each frame would linearly increase the model’s input. Then use some form of model that handles batches of sequential data, e.g., a 3D <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">CNN</a> or <a href="https://en.wikipedia.org/wiki/Attention_%28machine_learning%29">attention</a> layer. These models would have heavily slowed down training and require more VRAM than I had at the time</li>
<li>Use a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a> such as an <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM</a>.</li>
<li>Use a <a href="https://huggingface.co/blog/lbourdois/get-on-the-ssm-train">state space model</a> (SSM).</li>
</ul>
<p>I went with the easiest to integrate solution, an LSTM. An LSTM contains an internal state that gets input to the model alongside the most recent data point. Although LSTMs can only remember up to ≈1000 steps, that was enough history for an effective policy.</p>
<p>The policy ended up being ≈10 million parameters or 40MB. For context, that&rsquo;s 5 orders of magnitude smaller than DeepSeek. Enough to fit on the average consumer GPU.</p>
<h2 id="feature-engineering-the-policy">
  Feature Engineering the Policy
  <a class="anchor" href="#feature-engineering-the-policy">#</a>
</h2>
<p>I mentioned the observation I input to the policy, but did not mention its members’ <em>data types</em>. As I’ll explain later, I wanted to keep the size (in bytes) of the observation as small as possible. I also needed to transform the observation into a form the model dictating the policy could use for optimization.</p>
<h3 id="Pokémon-red-policy">
  Pokémon Red Policy
  <a class="anchor" href="#Pokémon-red-policy">#</a>
</h3>
<details open><summary>Pokémon Red Policy</summary>
  <div class="markdown-inner">
<pre class="mermaid">
---
config:
  theme: mc
  look: handDrawn
---
flowchart LR
        Party_Network2["Party Network"]
        FinalConcat("Concat")
        Screen_Network2["Screen Network"]
        MapIDE("Map ID Embeddings")
        MapID("Map ID")
        MapIDE2("Map ID Embeddings")
        BlackoutMapId("Blackout Map ID")
        Mul("x")
        ItemIDE("Item ID Embeddings")
        BagItemIds("Bag Item IDs")
        div100("/ 100")
        BagItemQ("Bag Item Quantities")
        Events("Events Completed Array")
        OneHot("One-hot")
        Direction("Direction")
        OneHot2("One-hot")
        BattleT("Battle Type")
        MissingEvents2("Missing Events")
        div502("/ 502.0")
        SafariZoneSteps("Safari Zone Steps Remaining")
        LSTM("LSTM")
        Linear3("Linear")
    Party_Network2 --> FinalConcat
    Screen_Network2 --> FinalConcat
    MapID --> MapIDE
    MapIDE --> FinalConcat
    BlackoutMapId --> MapIDE2
    MapIDE2 --> FinalConcat
    BagItemIds --> ItemIDE
    ItemIDE --> Mul
    BagItemQ --> div100
    div100 --> Mul
    Mul --> FinalConcat
    Events --> FinalConcat
    Direction --> OneHot
    OneHot --> FinalConcat
    BattleT --> OneHot2
    OneHot2 --> FinalConcat
    MissingEvents2 --> FinalConcat
    SafariZoneSteps --> div502
    div502 --> FinalConcat
    FinalConcat --> Linear3
    Linear3 --> LSTM
</pre>
  </div>
</details>
<details ><summary>Party Network</summary>
  <div class="markdown-inner">
<pre class="mermaid">
---
config:
  theme: mc
  look: handDrawn
---
flowchart LR
        Concat("Concat")
        SIDE("Species Embeddings")
        SID("Species ID")
        Hp("HP")
        Status("Status")
        t1e("Type Embeddings")
        t1("Type 1")
        t2e("Type Embeddings")
        t2("Type 2")
        level("Level")
        MaxHp("Max HP")
        Attack("Attack")
        Defense("Defense")
        Special("Special")
        MovesE("Moves Embeddings")
        Moves("Moves")
        Flatten1("Flatten")
        Linear2("Linear")
        Linear1("Linear")
    SID --> SIDE
    SIDE --> Concat
    Hp --> Concat
    Status --> Concat
    t1 --> t1e
    t1e --> Concat
    t2 --> t2e
    t2e --> Concat
    level --> Concat
    MaxHp --> Concat
    Attack --> Concat
    Defense --> Concat
    Special --> Concat
    Moves --> MovesE
    MovesE --> Concat
    Concat --> Linear1
    Linear1 --> Linear2
    Linear2 --> Flatten1
</pre>
  </div>
</details>
<details ><summary>Screen Network</summary>
  <div class="markdown-inner">
<pre class="mermaid">
---
config:
  theme: mc
  look: handDrawn
---
flowchart LR
        Concat2("Concat")
        gamescreen("Game Screen<br>72x80x1<br>grayscale")
        visitedmask("Visited Mask<br>72x80")
        relu1("ReLU")
        Conv1("2D CNN<br>72x80x2")
        relu2("ReLU")
        Conv2("2D CNN<br>72x80x32")
        relu3("ReLU")
        Conv3("2D CNN<br>36x40x64")
        relu4("ReLU")
        Conv4("2D CNN<br>18x20x64")
        Flatten2("Flatten")
    gamescreen --> Concat2
    visitedmask --> Concat2
    Concat2 --> Conv1
    Conv1 --> relu1
    relu1 --> Conv2
    Conv2 --> relu2
    relu2 --> Conv3
    Conv3 --> relu3
    relu3 --> Conv4
    Conv4 --> relu4
    relu4 --> Flatten2
</pre>
  </div>
</details>
<details ><summary>Missing Events</summary>
  <div class="markdown-inner">
<pre class="mermaid">
---
config:
  theme: mc
  look: handDrawn
---
flowchart TB
        Rival3("Rival 3 Defeated Boolean")
        Lapras("Lapras Acquired Boolean")
        SaffronGuard("Drink Given Saffron Guard Boolean")
        GameCornerRocket("Game Corner Rocket")
</pre>
  </div>
</details>
<p>Let’s summarize what the observation consists of:</p>
<table>
  <thead>
      <tr>
          <th style="text-align: center">Observation</th>
          <th style="text-align: center">Shape</th>
          <th style="text-align: center">Data Type</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">Screen</td>
          <td style="text-align: center">72x80x1</td>
          <td style="text-align: center">int</td>
      </tr>
      <tr>
          <td style="text-align: center">Visited Mask</td>
          <td style="text-align: center">72x80x1</td>
          <td style="text-align: center">int</td>
      </tr>
      <tr>
          <td style="text-align: center">Map ID</td>
          <td style="text-align: center">1x1</td>
          <td style="text-align: center">int</td>
      </tr>
      <tr>
          <td style="text-align: center">Blackout Map ID</td>
          <td style="text-align: center">1x1</td>
          <td style="text-align: center">int</td>
      </tr>
      <tr>
          <td style="text-align: center">Item IDs</td>
          <td style="text-align: center">20x1</td>
          <td style="text-align: center">int</td>
      </tr>
      <tr>
          <td style="text-align: center">Item Quantities</td>
          <td style="text-align: center">20x1</td>
          <td style="text-align: center">int</td>
      </tr>
      <tr>
          <td style="text-align: center">Agent Party</td>
          <td style="text-align: center">6x11</td>
          <td style="text-align: center">int</td>
      </tr>
      <tr>
          <td style="text-align: center">Events Array</td>
          <td style="text-align: center">1x2560</td>
          <td style="text-align: center">boolean</td>
      </tr>
      <tr>
          <td style="text-align: center">Direction</td>
          <td style="text-align: center">1x1</td>
          <td style="text-align: center">int</td>
      </tr>
      <tr>
          <td style="text-align: center">Current Battle Condition</td>
          <td style="text-align: center">1x1</td>
          <td style="text-align: center">int</td>
      </tr>
      <tr>
          <td style="text-align: center">Rival 3 defeated</td>
          <td style="text-align: center">1x1</td>
          <td style="text-align: center">boolean</td>
      </tr>
      <tr>
          <td style="text-align: center">Lapras Acquired</td>
          <td style="text-align: center">1x1</td>
          <td style="text-align: center">boolean</td>
      </tr>
      <tr>
          <td style="text-align: center">Saffron Guard</td>
          <td style="text-align: center">1x1</td>
          <td style="text-align: center">boolean</td>
      </tr>
      <tr>
          <td style="text-align: center">Game Corner Rocket Defeated</td>
          <td style="text-align: center">1x1</td>
          <td style="text-align: center">boolean</td>
      </tr>
      <tr>
          <td style="text-align: center">Number of Safari Steps Remaining</td>
          <td style="text-align: center">1x1</td>
          <td style="text-align: center">int</td>
      </tr>
  </tbody>
</table>
<p>In the policy, I occasionally normalize the value by some constant. In machine learning, it is generally adviseable represent these numbers as values between 0 and 1 for model stability.</p>
<h2 id="the-cnn">
  The CNN
  <a class="anchor" href="#the-cnn">#</a>
</h2>
<p>The screen obs and visited mask were concatenated together to make 2 visual “channels”. These channels were passed to a 2D Convolutional Neural Network (CNN). The kernel sizes of the CNN were designed with the GameBoy&rsquo;s in mind.</p>
<p>The first layer of the CNN used an 8x8 kernel mapping to the size of a gameboy tile with a stride of size 2 so inter-tile dependencies could be detected. In successive layers, I decreased the kernel size so as not to capture too much information and similarly stride by 2 each layer so that the agent can hopefully get a good sense for edge detection.</p>
<h2 id="one-hot-encoding">
  One-Hot encoding
  <a class="anchor" href="#one-hot-encoding">#</a>
</h2>
<p>One hot encoding is a convenient technique to take a value representing a category and map it to a representation useful for the model. It&rsquo;s useful when the number of categories is low.</p>
<p>Of the observations, direction, battle state (in-battle, wild battle, trainer battle) are represented as one-hot encoded values.</p>
<h2 id="embeddings">
  Embeddings
  <a class="anchor" href="#embeddings">#</a>
</h2>
<p>The map ID and blackout map IDs are passed to the policy as integers, but in the policy, I transform them them with an embedding layer. Embedding layers are a convenient way to handle decreasing the number of dimensions of a categorical input. Instead of a one hot encoding the map id with # map id channels, I only require 5 floats to accurately represent the map id space. I chose 5 based on a recommendation from <a href="https://developers.google.com/machine-learning/crash-course">Google&rsquo;s Machine Learning Crash Course</a>. Google recommends using # of rows^.25 for the number of dimensions in the embedding layer.</p>
<p>Items held in the agent&rsquo;s bag are also identified by ID. The Item IDs are passed to their own embedding layer. I scale the item embeddings by the item&rsquo;s quantities; a number between 0 and 1 where 0 maps to 0 and 1 maps the max number of the same item an agent can have.</p>
<h2 id="party-network">
  Party Network
  <a class="anchor" href="#party-network">#</a>
</h2>
<p>All party data is concatenated together and passed through a small dense layer to create a “Pokémon” space.</p>
<h2 id="binary-vectors">
  Binary Vectors
  <a class="anchor" href="#binary-vectors">#</a>
</h2>
<p>In RAM, events are a packed binary vector with each bit representing one in-game completed event. I unpack this vector and pass it on to the policy. The event vector in RAM does not include Lapras, Rival 3 and the Saffron Guard. I pass these in separately as they are &ldquo;event&rdquo;-like in my opinion.</p>
<h2 id="safari-steps">
  Safari Steps
  <a class="anchor" href="#safari-steps">#</a>
</h2>
<p>The num of steps left in the Safari Zone is in the range [0, 502]. I normalize the steps observation to a value between 0 and 1 where 0 means no steps are left and 1 means you have the max number of steps remaining.</p>
<h2 id="final-model-layers">
  Final Model Layers
  <a class="anchor" href="#final-model-layers">#</a>
</h2>
<p>Once all features have been transformed, all non-batch dimension data is flattened, concatenated and passed through a final linear layer before heading to the LSTM. The LSTM is an off the shelf component and not worth discussing.</p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#feature-engineering-the-policy">Feature Engineering the Policy</a>
      <ul>
        <li><a href="#Pokémon-red-policy">Pokémon Red Policy</a></li>
      </ul>
    </li>
    <li><a href="#the-cnn">The CNN</a></li>
    <li><a href="#one-hot-encoding">One-Hot encoding</a></li>
    <li><a href="#embeddings">Embeddings</a></li>
    <li><a href="#party-network">Party Network</a></li>
    <li><a href="#binary-vectors">Binary Vectors</a></li>
    <li><a href="#safari-steps">Safari Steps</a></li>
    <li><a href="#final-model-layers">Final Model Layers</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












